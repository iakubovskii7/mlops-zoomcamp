{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1.6 Homework\n",
    "\n",
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q1. Downloading the data\n",
    "\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page),\n",
    "but instead of \"Green Taxi Trip Records\", we'll use \"For-Hire Vehicle Trip Records\"\n",
    "\n",
    "Download the data for January and February 2021\n",
    "\n",
    "Note that you need \"For-Hire Vehicle Trip Records\", not \"High Volume For-Hire Vehicle Trip Records\".\n",
    "\n",
    "Read the data for January. How many records are there?\n",
    "\n",
    "* 1054112\n",
    "* 1154112\n",
    "* 1254112\n",
    "* 1354112"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1154112\n"
     ]
    }
   ],
   "source": [
    "df_jan = pd.read_parquet(\"data/fhv_tripdata_2021-01.parquet\")\n",
    "print(df_jan.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q2. Computing duration\n",
    "\n",
    "Now let's compute the `duration` variable. It should contain the duration of a ride in minutes.\n",
    "\n",
    "What's the average trip duration in January?\n",
    "\n",
    "* 15.16\n",
    "* 19.16\n",
    "* 24.16\n",
    "* 29.16"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.167224093791006\n"
     ]
    }
   ],
   "source": [
    "df_jan['duration'] = (df_jan['dropOff_datetime'] - df_jan['pickup_datetime'])\\\n",
    "    .apply(lambda x: x.total_seconds() / 60)\n",
    "print(df_jan['duration'].mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preparation\n",
    "\n",
    "Check the distribution of the duration variable. There are some outliers.\n",
    "\n",
    "Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "How many records did you drop?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "1109826"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jan_prep = df_jan.query(\"duration >= 1 & duration <= 60\")\n",
    "df_jan_prep.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We dropped 44286 observations\n"
     ]
    }
   ],
   "source": [
    "print(f\"We dropped {df_jan.shape[0] - df_jan_prep.shape[0]} observations\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q3. Missing values\n",
    "\n",
    "The features we'll use for our model are the pickup and dropoff location IDs.\n",
    "\n",
    "But they have a lot of missing values there. Let's replace them with \"-1\"\n",
    "\n",
    "What's the factions of missing values for the pickup location ID? (Or the fraction of \"-1\"s after you filled the NAs)\n",
    "\n",
    "* 53%\n",
    "* 63%\n",
    "* 73%\n",
    "* 83%"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "dispatching_base_num            0\npickup_datetime                 0\ndropOff_datetime                0\nPUlocationID               927008\nDOlocationID               147907\nSR_Flag                   1109826\nAffiliated_base_number        773\nduration                        0\ndtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jan_prep.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1109826 entries, 0 to 1154111\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Non-Null Count    Dtype         \n",
      "---  ------                  --------------    -----         \n",
      " 0   dispatching_base_num    1109826 non-null  object        \n",
      " 1   pickup_datetime         1109826 non-null  datetime64[ns]\n",
      " 2   dropOff_datetime        1109826 non-null  datetime64[ns]\n",
      " 3   PUlocationID            182818 non-null   float64       \n",
      " 4   DOlocationID            961919 non-null   float64       \n",
      " 5   SR_Flag                 0 non-null        float64       \n",
      " 6   Affiliated_base_number  1109053 non-null  object        \n",
      " 7   duration                1109826 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(4), object(2)\n",
      "memory usage: 76.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_jan_prep.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "cols_fill_miss = ['PUlocationID', 'DOlocationID']\n",
    "for col in cols_fill_miss:\n",
    "   df_jan_prep[col] =  df_jan_prep[col].fillna(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the factions of missing values for the pickup location ID = 83.53% \n"
     ]
    }
   ],
   "source": [
    "share_of_miss_PU = df_jan_prep.query('PUlocationID == -1').shape[0] / df_jan_prep.shape[0]\n",
    "print(f\"the factions of missing values for the pickup location ID = {np.round(share_of_miss_PU * 100, 2)}% \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "* Turn the dataframe into a list of dictionaries\n",
    "* Fit a dictionary vectorizer\n",
    "* Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix? (The number of columns)\n",
    "\n",
    "* 2\n",
    "* 152\n",
    "* 352\n",
    "* 525\n",
    "* 725"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "train_dicts = df_jan_prep[cols_fill_miss].to_dict(orient='records')\n",
    "dv = DictVectorizer(sparse=False)\n",
    "ohe = OneHotEncoder()\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "X_train_ohe = ohe.fit_transform(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dimensionality of this matrix is (1109826, 525)\n"
     ]
    }
   ],
   "source": [
    "print(f\"the dimensionality of this matrix is {X_train_ohe.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "* Train a plain linear regression model with default parameters\n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "* 5.52\n",
    "* 10.52\n",
    "* 15.52\n",
    "* 20.52"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for linear regression = 10.53\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lr = LinearRegression()\n",
    "target = 'duration'\n",
    "y_train = df_jan_prep[target].values\n",
    "\n",
    "lr.fit(X_train_ohe, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_train_ohe)\n",
    "\n",
    "print(f\"RMSE for linear regression on train = {np.round(mean_squared_error(y_train, y_pred, squared=False), 2)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (Feb 2021).\n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "* 7.85\n",
    "* 12.85\n",
    "* 17.85\n",
    "* 22.85"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories [110.0] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [40]\u001B[0m, in \u001B[0;36m<cell line: 11>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      9\u001B[0m val_dicts \u001B[38;5;241m=\u001B[39m df_feb_prep[cols_fill_miss]\u001B[38;5;241m.\u001B[39mto_dict(orient\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrecords\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     10\u001B[0m X_val \u001B[38;5;241m=\u001B[39m dv\u001B[38;5;241m.\u001B[39mtransform(val_dicts)\n\u001B[0;32m---> 11\u001B[0m X_val_ohe \u001B[38;5;241m=\u001B[39m \u001B[43mohe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mlops-zoomcamp/venv/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:882\u001B[0m, in \u001B[0;36mOneHotEncoder.transform\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# validation of X happens in _check_X called by _transform\u001B[39;00m\n\u001B[1;32m    878\u001B[0m warn_on_unknown \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdrop \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_unknown \u001B[38;5;129;01min\u001B[39;00m {\n\u001B[1;32m    879\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    880\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minfrequent_if_exist\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    881\u001B[0m }\n\u001B[0;32m--> 882\u001B[0m X_int, X_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhandle_unknown\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_unknown\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwarn_on_unknown\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwarn_on_unknown\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    887\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    888\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_infrequent_categories(X_int, X_mask)\n\u001B[1;32m    890\u001B[0m n_samples, n_features \u001B[38;5;241m=\u001B[39m X_int\u001B[38;5;241m.\u001B[39mshape\n",
      "File \u001B[0;32m~/mlops-zoomcamp/venv/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:160\u001B[0m, in \u001B[0;36m_BaseEncoder._transform\u001B[0;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown)\u001B[0m\n\u001B[1;32m    155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m handle_unknown \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124merror\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    156\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    157\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound unknown categories \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m in column \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    158\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m during transform\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(diff, i)\n\u001B[1;32m    159\u001B[0m     )\n\u001B[0;32m--> 160\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m warn_on_unknown:\n",
      "\u001B[0;31mValueError\u001B[0m: Found unknown categories [110.0] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "df_feb = pd.read_parquet(\"data/fhv_tripdata_2021-02.parquet\")\n",
    "df_feb_prep = df_feb\\\n",
    "    .assign(\n",
    "    duration=lambda x: x['dropOff_datetime'] - x['pickup_datetime'])\\\n",
    "    .assign(\n",
    "    duration=lambda x: x['duration'].apply(lambda td: td.total_seconds() / 60))\\\n",
    "    .query(\"1<=duration<=60\")\n",
    "df_feb_prep[cols_fill_miss] = df_feb_prep[cols_fill_miss].fillna(-1)\n",
    "val_dicts = df_feb_prep[cols_fill_miss].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "X_val_ohe = ohe.transform(X_val)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "60.0"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feb_prep['duration'].max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}